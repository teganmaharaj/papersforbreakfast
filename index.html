<!DOCTYPE html>
<html>
	<head>
		<title>Papers for breakfast ... mmm</title>
		<link rel="stylesheet" type="text/css" href="/css/main.css">
		<style>
			body {
			    margin: 60px auto;
			    width: 70%;
			    background-color: #fff2e6;
			}
			nav ul, footer ul {
			    font-family:'Helvetica', 'Arial', 'Sans-Serif';
			    padding: 0px;
			    list-style: none;
			    font-weight: bold;
			}
			nav ul li, footer ul li {
			    display: inline;
			    margin-right: 20px;
			}
			a {
			    text-decoration: none;
			    color: #999;
			}
			a:hover {
			    text-decoration: underline;
			}
			h1 {
			    font-size: 3em;
			    font-family:'Helvetica', 'Arial', 'Sans-Serif';
			}
			h2 {
			    font-size: 2em;
			    font-family:'Helvetica', 'Arial', 'Sans-Serif';
			}
			p {
			    font-size: 1.5em;
			    font-family:'Helvetica', 'Arial', 'Sans-Serif';
			    line-height: 1.4em;
			    color: #333;
			}
			footer {
			    border-top: 1px solid #d5d5d5;
			    font-size: .8em;
			}

			ul.posts { 
			    margin: 20px auto 40px; 
			    font-size: 1.5em;
			}

			ul.posts li {
			    list-style: none;
			}
			
			div.title_blurb {
			    background-color: #fff2e6;
			}
			div.blurb {
			    background-color: #ffffff;
			    width: 75%;
		            padding: 10%;
			}
			
		</style>
	</head>
	<body>
		<nav>
    		<ul>
        		<li><a href="/">Home</a></li>
	        	<li><a href="/about">About</a></li>
			<li><a href="/blog">Blog</a></li>
        		<li><a href="/other_res">Other resources</a></li>
    		</ul>
		</nav>
    
		<div class="container">
    		<div class="title_blurb">
        		<h1>Papers for Breakfast</h1>
				<p>Full of science-fibre; a delicious and digestible way to start your day!</p>
    		</div><!-- /.blurb -->
		</div><!-- /.container -->
    
		<div class="container">
    		<div class="blurb">
        		<h1>Unsupervised Pixelâ€“Level Domain Adaptation with Generative Adversarial Networks</h1>
			<p><a href="https://arxiv.org/abs/1612.05424"></a></p>
		
			<p>Domain adaptation is a problem setup where you have a lot of labelled data in a "source domain" (e.g. a simulator, synthesizer, white-background product photos, etc.), and a small amount of/expensive labelled data in a "target domain" (e.g. a real robot, real speech, natural images), and you want to be able to learn from the source domain and generalize to the target domain. </p>
<p>
 Prior work focused a lot on learning domain-invariant features which would be equally applicable to both source and target, usually suffering a loss in performance as you take a source-trained model and apply it to the target domain. </p>
<p>
This paper proposes instead to learn (unsupervised) a mapping from source domain to target domain (e.g. sim to real) images, and train on that. They use a GAN to learn the mapping in pixel space, and then train on target and generated images.  </p>
<p>
They do experiments on MNIST -> USPS (I hadn't heard of it before; looks like MNIST with blur-sharpened edges), MNIST-> MNIST_M (coloured MNIST on natural-ish backgrounds), and Linemod (object recognition and pose estimation in cluttered scenes; ~100 000 rendered and 1000 real). I'm not very familiar with these as benchmarks, but they all seem quite small. Their method is able to outperform the 'Target-only" benchmark (i.e. don't use the source data, don't do domain adaptation), which is apparently difficult to achieve. </p>

<p>
Overall, the method sounds very appealing to me; I like the concept, but feel like there need to be larger/maybe differently-designed benchmarks to really compare different methods. I find it discouraging in general to know that it's difficult to improve over 'target-only' methods. It feels like this shouldn't be the case, but I guess this is just the story of semi-supervised learning at the moment. I wonder if this is more/mostly to do with:  </p>
<p><ol>
	<li>benchmark dataset size	</li>
	<li>evaluation criteria/task setup 	</li>
	<li>model architecture	</li>
	<li>combination of the above, indicating that we're currently overfitting on maybe a lot of tasks in a way that is maybe difficult to measure 	</li>
	<li>something mysteriously difficult about semisupervised learning that is not currently understood
	<li>something else?	</li>	
			</ol>
			</p>
						<p>
				They also make an interesting and easy-to-miss connection with InfoGAN in the appendix. If you use their approach for classification, like InfoGAN, it amounts to a variational method for maximizing the mutual information between the predicted class and generated/source images.
			</p>			
			
    		</div><!-- /.blurb -->
		</div><!-- /.container -->
		
		<!--
    <div class="container">
    		<div class="blurb">
        		<h1>Inferring and Executing Programs for Visual Reasoning</h1>
			<p><a href="https://arxiv.org/abs/1705.03633"></a></p> -->
    		<!--</div> /.blurb -->
		<!--</div> /.container -->
		
		
		
		<footer>
    		<ul>
        		<li><a href="mailto:tegan.maharaj@gmail.com">email</a></li>
        		<li><a href="https://github.com/teganmaharaj">github.com/teganmaharaj</a></li>
        		<li><a href="https://teganmaharaj.com">teganmaharaj.com</a></li>
        		<li><a href="https://scholar.google.ca/citations?user=XpscC-EAAAAJ&hl=en">scholar</a></li>
			</ul>
		</footer>
	</body>
</html>
